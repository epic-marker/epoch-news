### 闻所未闻 白宫派遣黑客大战最强AI

---

#### [首页](../../../..?n14052474) &nbsp;|&nbsp; [评论](../../../../../epoch-comment?n14052474) &nbsp;|&nbsp; [专题](../../../../../epoch-special?n14052474) &nbsp;|&nbsp; [禁闻](../../../../../epoch-news?n14052474) &nbsp;|&nbsp; [禁书](../../../../../books?n14052474) &nbsp;|&nbsp; [翻墙](https://github.com/gfw-breaker/nogfw/blob/master/README.md?n14052474)


<div><img alt="闻所未闻 白宫派遣黑客大战最强AI" class="attachment-djy_600_400 size-djy_600_400 wp-post-image" src="https://i.epochtimes.com/assets/uploads/2023/05/id14007068-166476-600x400.jpeg"/>
<div class="caption">
 近期以ChatGPT为代表的人工智能的发展，引起广泛注意。(Shutterstock)
</div></div><hr/><div class="post_content" id="artbody" itemprop="articleBody">
 <!-- article content begin -->
 <p>
  【大纪元2023年08月11日讯】（大纪元记者程雯综合报导）8月11日（周五），一小队
  <ok href="https://www.epochtimes.com/gb/tag/%E9%BB%91%E5%AE%A2.html">
   黑客
  </ok>
  将对OpenAI、谷歌和Meta等科技巨头公司旗下的世界上最强大的
  <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.html">
   人工智能
  </ok>
  （AI）系统发起攻击。
  <ok href="https://www.epochtimes.com/gb/tag/%E7%99%BD%E5%AE%AB.html">
   白宫
  </ok>
  官员公开表示，这起前所未有的由白宫派遣
  <ok href="https://www.epochtimes.com/gb/tag/%E9%BB%91%E5%AE%A2.html">
   黑客
  </ok>
  大战超强AI行动的指令是“来自总统（拜登）”。
 </p>
 <p>
  这次黑客攻击凸显出
  <ok href="https://www.epochtimes.com/gb/tag/%E7%99%BD%E5%AE%AB.html">
   白宫
  </ok>
  对强大的、快速发展的新AI模型的
  <ok href="https://www.epochtimes.com/gb/tag/%E5%AE%89%E5%85%A8.html">
   安全
  </ok>
  威胁到底有多大的担忧。
 </p>
 <p>
  同时，美国的政策制定者和技术专家们也在大声呼吁美国尽快推出
  <ok href="https://www.epochtimes.com/gb/tag/%E7%AB%8B%E6%B3%95.html">
   立法
  </ok>
  ，对AI及其发展进行监管，他们尤其担心AI可能会威胁到人类的生存，以及一旦由中共制定的AI规范在全球范围延申开来，会给人权和隐私带来何种威胁。
 </p>
 <h4>
  <strong>
   黑客大战世界最强AI
  </strong>
 </h4>
 <p>
  据“政客”（Politico）新闻网8月10日报导，拜登政府在今年5月已经计划了，于本周末（8月11日）在拉斯维加斯召开的年度黑客大会上，对AI系统进行为期三天的蓄意的协同测试攻击，黑客军团在这次演习中被称为“红队”。包括OpenAI、谷歌和Meta等在内的几家世界领先的
  <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.html">
   人工智能
  </ok>
  公司同意让其最新、最强大的AI系统在这次演习中受到攻击。
 </p>
 <p>
  这次活动凸显了白宫对AI的主要担忧之一：AI的
  <ok href="https://www.epochtimes.com/gb/tag/%E5%AE%89%E5%85%A8.html">
   安全
  </ok>
  性到底如何？AI是否会对美国公民或在全球对美国国家安全构成威胁？
 </p>
 <p>
  白宫科技政策办公室高级官员艾伦‧米斯洛夫（Alan Mislove）说：“我们的构想是——这是来自总统的（指令）——为了对AI有驾驭的机会，我们首先也需要管理风险。”
 </p>
 <p>
  米斯洛夫帮助组建了进行这次黑客挑战演习赛的“红队”——从黑客大会上经验丰富的与会者到专程为此次挑战飞来的社区学院学生。他说：“对于像大型语言模型这样的东西，这些风险相当广泛，在许多情况下可能不如其它系统那么明确，且涵盖了我们的社会、我们的经济和国家安全。”
 </p>
 <p>
  随着国会在努力确定要通过哪些新法律以监管AI，以及联邦机构对AI行使现有法规的权力，拜登政府已成为AI政策方面最积极的参与者。就AI技术带来的广泛威胁和机遇，拜登政府已经起草了一份《人工智能权利法案》（AI Bill of Rights）的框架，他们还召集了与大科技公司首席执行官们的会议，并就该技术带来的各种威胁和机遇问题举行了一系列新闻发布会。
 </p>
 <p>
  尽管AI带来的威胁涉及整个社会，从替代劳动力导致失业，到带来歧视，再到虚假和错误信息传播等，不过白宫的许多最切实的措施都集中在安全问题上。
 </p>
 <p>
  白宫的新任AI特别顾问本‧布坎南（Ben Buchanan）拥有国家安全背景，而非技术背景。上个月，当白宫召集人工智能领袖开会宣布一系列自愿承诺时，“安全”一词也高居关键词榜首。
 </p>
 <p>
  对AI安全性的高度重视反映了专家、监管机构和行业本身的焦虑，即复杂的新AI系统带来了一系列尚未完全理解的新的安全问题，例如它们可能被黑客攻击和被对手用于误导我们，它们也可能会暴露用户数据，甚至被用于制造生物武器等更黑暗的用途。
 </p>
 <p>
  白宫科技政策办公室主任阿拉蒂‧普拉巴卡尔（Arati Prabhakar）说：“让这些（AI）模型做一些它们的设计者和供应商没有预料到或不想让它们做的事情，这是可能的。所以，是的，我认为确实要（对于AI）有安全方面的考虑。”
 </p>
 <p>
  不过另一方面，AI也可以成为提高安全性的工具。本周，五角大楼宣布了一项为期两年的艰巨任务，要求开发人员使用AI来强化美国关键的网络安全。
 </p>
 <p>
  五角大楼等政府机构此前还曾向黑客社区寻求网络安全问题，以弥补该无处不在的新技术中的漏洞。
 </p>
 <p>
  该黑客大会历年来都会举办黑客攻击游戏，网络安全专业人士会在大会上揭示最新技术漏洞，而今年的政府支持和行业参与程度都不同寻常。科技公司传统上不愿意将其专有软件公开给公众进行测试。但今年，在白宫的敦促下，OpenAI、Anthropic、谷歌、Hugging Face、英伟达（NVIDIA）、Meta、Cohere和Stability等科技公司都提供了他们的大型AI语言模型以供审查。他们还将提供他们的语言模型的封闭版本，以供一系列黑客攻击演习。
 </p>
 <p>
  不过，这次大战演习的结果要到明年2月才会公开，这让科技公司有时间修复它们的安全漏洞，因为对AI来说，这个过程比较复杂。Meta的安全研究员克里斯‧罗尔夫（Chris Rohlf）说：“这并不像修补软件缺陷那么简单。”
 </p>
 <p>
  尽管这次黑客攻击演习很是高调和大张旗鼓，不过演习本身不可能揭示AI系统可能会出现的所有错误行为和漏洞，尤其是因为每名黑客侵入一个大型语言模型的时间非常有限，每次尝试只给大约50分钟，而且仅限于大会活动中可用的技术设备。
 </p>
 <p>
  白宫希望，未来能有更大规模的多方参与的广泛红队演习。
 </p>
 <h4>
  <strong>
   网络法专家：美国需加快对
  </strong>
  <strong>
   AI
  </strong>
  <strong>
   的监管
   <ok href="https://www.epochtimes.com/gb/tag/%E7%AB%8B%E6%B3%95.html">
    立法
   </ok>
  </strong>
 </h4>
 <p>
  美国匹兹堡大学的“网络法、政策和安全研究所”的创始所长大卫‧希克托（David Hickton）敦促美国国会加快对AI监管的立法行动，不要落在其它国家后面。
 </p>
 <p>
  也曾担任过宾夕法尼亚州西区联邦检察官的希克托8月6日在《国会山报》上撰文提到，欧盟计划在2023年底前通过《欧盟人工智能法案》（EU AI Act），而英国的行动比欧盟还迅速，他们计划在2023年秋季举行的国际AI峰会上宣布他们的AI法规。
 </p>
 <p>
  希克托还提到，中国也已经制定了多项AI监管政策，但是被要求“体现社会主义核心价值观”。这种AI政策在中国国内的实践预示了，由中共制定的AI规范在全球会是什么样子
  <strong>
   ：
  </strong>
  他们利用AI面部识别技术来侵犯人权和损害隐私。
 </p>
 <p>
  在该文中，希克托强调，如许多人所观察到的那样，AI“既能改善我们的生活，也能破坏我们的生活”，甚至还会威胁到人类的生存。政策制定者和技术专家因此都在大声呼吁加快对AI的监管立法。
 </p>
 <p>
  他敦促美国国会必须紧急采取行动，通过一项加强型的法规对AI实施监管，以防止AI可能会扰乱劳动力市场、威胁数据隐私、重塑选举和媒体生态等等的情况。
 </p>
 <p>
  对于快速发展的AI技术来说，尽快出台监管立法并不是一件容易的事。希克托建议华盛顿可以在此前三届联邦政府针对AI的使用及其风险的努力的基础上，加快目前的监管立法步伐，这也可为AI大科技公司们最近达成的自愿协议增加力度和增添具体内容。此外，现有的关于非歧视、知识产权和消费者保护的联邦法律也应该可以被用来围绕AI监管建立初步的法律护栏。
 </p>
 <p>
  希克托希望美国能够越快立法越好，因为这将加强美国在网络外交方面的谈判地位，让美国在塑造全球AI生态系统方面发挥带头作用。
 </p>
 <p>
  责任编辑：李琳#
 </p>
 <!-- article content end -->
 <div id="below_article_ad">
 </div>
</div>


<img src='http://gfw-breaker.win/epoch-news/pages/ncid1078159/n14052474.md' width='0px' height='0px'/>

---

原文链接（需翻墙）：https://www.epochtimes.com/gb/23/8/11/n14052474.htm